(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{334:function(e,t,a){"use strict";a.r(t);var s=a(7),r=Object(s.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h2",{attrs:{id:"short-summary-short-summary"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#short-summary-short-summary"}},[e._v("#")]),e._v(" Short Summary {#short-summary}")]),e._v(" "),t("p",[e._v("This paper proposed a NAND-flash SSD-friendly full text engine. This engine can\nachieve better performance than existing engines with much less memory requested.")]),e._v(" "),t("p",[e._v("They reduce the unnecessary I/O (both the number of I/O and the volume). The\nengine does not cache data into memory, instead, read data every time when query\narrive.")]),e._v(" "),t("p",[e._v("They also tried to increase the request size to exploit SSD internal parallelism.")]),e._v(" "),t("h2",{attrs:{id:"what-is-the-problem-what-is-the-problem"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#what-is-the-problem-what-is-the-problem"}},[e._v("#")]),e._v(" What Is the Problem {#what-is-the-problem}")]),e._v(" "),t("p",[e._v("Search engines pose great challenges to storage systems:")]),e._v(" "),t("ul",[t("li",[e._v("low latency")]),e._v(" "),t("li",[e._v("high data throughput")]),e._v(" "),t("li",[e._v("high scalability")])]),e._v(" "),t("p",[e._v("The datasets become too large to fit into the RAM. Simply use RAM as a cache\ncannot achieve the goal.")]),e._v(" "),t("p",[e._v("SSD and NVRAM can boost performance well. For example, flash-based SSDs provide\nmuch higher throughput and lower latency compared to HDD.\nHowever, since SSDs exhibit vastly different characteristic from HDDs, we need\nto evolve the software on top of the storage stack to exploit the full potential\nof SSDs.")]),e._v(" "),t("p",[e._v("In this paper, the authors rebuild a search engine to better utilize SSDs to\nachieve the necessary performance goals with main memory that is significantly\nsmaller than the data set.")]),e._v(" "),t("h2",{attrs:{id:"why-the-problem-is-interesting-why-the-problem-is-interesting"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#why-the-problem-is-interesting-why-the-problem-is-interesting"}},[e._v("#")]),e._v(" Why the Problem Is Interesting {#why-the-problem-is-interesting}")]),e._v(" "),t("p",[e._v("There are already many studies that work on making SSD-friendly softwares within storage stack. For example, RocksDB, Wisckey (KV-store); FlashGraph, Mosaic (graphs processing); and SFS, F2fS (file system).")]),e._v(" "),t("p",[e._v("However, there is no optimization for full-text search engines.\nAlso the challenge of making SSD-friendly search engine is different with other categories of SSD-friendly softwares.")]),e._v(" "),t("h2",{attrs:{id:"the-idea-the-idea"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#the-idea-the-idea"}},[e._v("#")]),e._v(" The Idea {#the-idea}")]),e._v(" "),t("p",[e._v("The key idea is: "),t("strong",[e._v("read as needed")]),e._v(".")]),e._v(" "),t("p",[e._v("The reason behind of the idea is SSD can provide millisecond-level read latency,\nwhich is fast enough to avoid cache data into main memory.")]),e._v(" "),t("p",[e._v("There are three challenges:")]),e._v(" "),t("ol",[t("li",[e._v("reduce read amplification")]),e._v(" "),t("li",[e._v("hide I/O latency")]),e._v(" "),t("li",[e._v("issue large requests to exploit SSD performance")])]),e._v(" "),t("p",[e._v("(This work is focus on the data structure, inverted index. This is a commonly used data structure in the information retrieve system. There are some brief introduction about the inverted index in the paper, and I do not repeat the content here.)")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Category")]),e._v(" "),t("th",[e._v("Techniques")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("Reduce read amplification")]),e._v(" "),t("td",[e._v("- cross-stage data grouping")])]),e._v(" "),t("tr",[t("td"),e._v(" "),t("td",[e._v("- two-way cost-aware bloom filters")])]),e._v(" "),t("tr",[t("td"),e._v(" "),t("td",[e._v("- trade disk space for I/O")])]),e._v(" "),t("tr",[t("td",[e._v("Hide I/O latency")]),e._v(" "),t("td",[e._v("adaptive prefetching")])]),e._v(" "),t("tr",[t("td",[e._v("Issue large requests")]),e._v(" "),t("td",[e._v("cross-stage data grouping")])])])]),e._v(" "),t("h3",{attrs:{id:"cross-stage-data-grouping-cross-stage-data-grouping"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cross-stage-data-grouping-cross-stage-data-grouping"}},[e._v("#")]),e._v(" Cross-stage data grouping {#cross-stage-data-grouping}")]),e._v(" "),t("p",[e._v("This technique is used to reduce read amplification and issue large requests.")]),e._v(" "),t("p",[e._v("WiSER puts data needed for different stages of a query into continuous and compact blocks on the storage device, which increases block utilization when transferring data for query.\nInverted index of WiSER places data of different stages in the order that it will be accessed.")]),e._v(" "),t("p",[e._v("Previous search engines used to store data of different stages into different range, which reduces the I/O size and increases the number of I/O requests.")]),e._v(" "),t("h3",{attrs:{id:"two-way-cost-aware-filters-two-way-cost-aware-filters"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#two-way-cost-aware-filters-two-way-cost-aware-filters"}},[e._v("#")]),e._v(" Two-way Cost-aware Filters {#two-way-cost-aware-filters}")]),e._v(" "),t("p",[e._v("When doing phrase queries we need to use the position information to check the terms around a specific term to improve search precision.")]),e._v(" "),t("p",[e._v("The naive approach is to read the positions from all the terms in the phrase\nthen iterate the position list.\nTo reduce the unnecessary reading, WiSER employs a bitmap-based bloom filter.\nThe reason to use bitmap is to reduce the size of bloom filter. There are many\nempty entries in the filter array, use bitmap can avoid the waste.")]),e._v(" "),t("p",[t("em",[e._v("Cost-aware")]),e._v(" means comparing the size of position list with that of the bloom\nfilters. If the size of position list is smaller than that of bloom filters,\nWiSER reads the position list directly.")]),e._v(" "),t("p",[e._v("Two-way filters shares the same idea. WiSER chooses to read the smaller bloom\nfilter to reduce the read amplification.")]),e._v(" "),t("h3",{attrs:{id:"adaptive-prefetching-adaptive-prefetching"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#adaptive-prefetching-adaptive-prefetching"}},[e._v("#")]),e._v(" Adaptive Prefetching {#adaptive-prefetching}")]),e._v(" "),t("p",[e._v("Prefetching is one of the commonly used technique to hide the I/O latency.\nEven though, the read latency of SSD is small. Compare to DRAM, the read latency\nof SSD still much larger.")]),e._v(" "),t("p",[e._v("Previous search engines (e.g. Elasticsearch) use fix-sized prefecthing (i.e.\nLinux readahead) which increases the read amplification.\nWiSER defines an area called "),t("em",[e._v("prefetch zone")]),e._v(". A prefetch zone is further divided\ninto prefetch segments to avoid accessing too much data at a time. It prefetches when all prefetch zones involved in a query are larger than a threshold.")]),e._v(" "),t("p",[e._v("To enable adaptive prefetch, WiSER hides the size of the prefetch zone in the highest 16 bits of the offset in TermMap and calls "),t("code",[e._v("madvise()")]),e._v(" with the "),t("code",[e._v("MADV_SEQUENTIAL")]),e._v(" hint to readahead in the prefetch zone.")]),e._v(" "),t("h3",{attrs:{id:"trade-disk-space-for-i-o-trade-disk-space-for-i-o"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#trade-disk-space-for-i-o-trade-disk-space-for-i-o"}},[e._v("#")]),e._v(" Trade Disk Space for I/O {#trade-disk-space-for-i-o}")]),e._v(" "),t("p",[e._v("Engines like Elasticsearch put documents into a buffer and compresses all data in the buffer together. WiSER, instead, compresses each document by themselves.")]),e._v(" "),t("p",[e._v("Compressing all data in the buffer together achieves better compression.\nHowever, decompressing a document requires reading and decompressing all documents compressed before the document, leading to more I/O and computation. WiSER trades space for less I/O by using more space but reducing the I/O while processing queries.")]),e._v(" "),t("p",[e._v("In the evaluation, WiSER uses 25% more storage than Elasticsearch. The authors argue that the trade-off is acceptable in spite of the low RAM requirement of WiSER.")])])}),[],!1,null,null,null);t.default=r.exports}}]);