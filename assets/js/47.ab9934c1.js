(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{361:function(e,t,a){"use strict";a.r(t);var s=a(7),o=Object(s.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("blockquote",[t("p",[e._v("Because the course asks us to not sharing source code, here, I will only jot down some hits to help you (or maybe only me, kk) to finish the project. I will not even describe the process of any specific function, because I don't think that would be very different from public the source code.")])]),e._v(" "),t("h2",{attrs:{id:"task-1-page-layouts"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#task-1-page-layouts"}},[e._v("#")]),e._v(" Task #1 - Page Layouts")]),e._v(" "),t("p",[e._v("Because we want to persist the hash table instead of rebuild it every time, we need to design the layout that we use to store the hash table in the disks.")]),e._v(" "),t("p",[e._v("We have implemented the "),t("code",[e._v("BufferPoolManager")]),e._v(" in previous project. Buffer pool itself only allocate page frame for us to use. However, which kind of "),t("code",[e._v("Page")]),e._v(" is stored in the page frame? In this task, we need to create two kinds of "),t("code",[e._v("Page")]),e._v("s for our hash table:")]),e._v(" "),t("ul",[t("li",[e._v("Hash table directory page")]),e._v(" "),t("li",[e._v("Hash table bucket page")])]),e._v(" "),t("p",[e._v("Since we are using the previous allocated memory space (we cast the "),t("code",[e._v("data_")]),e._v(" field of "),t("code",[e._v("Page")]),e._v(" to directory page or bucket page), understanding of memory management and how C/C++ pointer operation works are necessary.")]),e._v(" "),t("p",[e._v("For bitwise operations, because the bitmap is based on char arrays, we can only do bitwise operations char by char (at least, this is what I find).")]),e._v(" "),t("h3",{attrs:{id:"hash-table-directory-page"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hash-table-directory-page"}},[e._v("#")]),e._v(" Hash Table Directory Page")]),e._v(" "),t("p",[e._v("This kind of page stores metadata for the hash table. The most important part is the "),t("strong",[e._v("bucket address table")]),e._v(".")]),e._v(" "),t("p",[e._v("At this stage, only implement the necessary functions, and they are very simple. We will come back to add more functions in the following tasks.")]),e._v(" "),t("h3",{attrs:{id:"hash-bucket-page"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hash-bucket-page"}},[e._v("#")]),e._v(" Hash Bucket Page")]),e._v(" "),t("p",[e._v("Stores key-value pairs, with some metadata that helps track space usages. Here, we only support fixed-length KV pairs.")]),e._v(" "),t("p",[e._v("There are two bitmaps that we used to indicate if a slot contains valid KV:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("readable_")])]),e._v(" "),t("li",[t("code",[e._v("occupied_")])])]),e._v(" "),t("p",[t("code",[e._v("occupied_")]),e._v(" actually has no specially meaning in extendible hashing because we do not need tombstone. However, we still need to maintain it, because there are some related test cases. I assume the teaching team still leave this part here so that they do not need to modify the test cases.")]),e._v(" "),t("p",[e._v("The page layout itself is very straightforward. Only the bitwise operations are a little annoying.")]),e._v(" "),t("h2",{attrs:{id:"task-2-hash-table-implementation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#task-2-hash-table-implementation"}},[e._v("#")]),e._v(" Task #2 - Hash Table Implementation")]),e._v(" "),t("p",[e._v("This task is very interesting because we use the buffer pool manager that we implemented previously to handle the storage part for thus. We only need to use these APIs to allocate pages and store the hash table in these pages.")]),e._v(" "),t("p",[e._v("I recommend to implement the search at the very beginning then other functions, since other operations also need search to check if a specific KV pair is existed.")]),e._v(" "),t("h3",{attrs:{id:"search"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#search"}},[e._v("#")]),e._v(" Search")]),e._v(" "),t("p",[e._v("For a given "),t("code",[e._v("key")]),e._v(", we use the given hash function to get the hash value, then through the directory (bucket address table) to get the corresponding bucket page. After that, we do a sequential search to find the key.")]),e._v(" "),t("p",[e._v("Because we support duplicated keys, we need to find all the KV pairs that has the given key. Do not stop at the first matched pair.")]),e._v(" "),t("h3",{attrs:{id:"insert"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#insert"}},[e._v("#")]),e._v(" Insert")]),e._v(" "),t("p",[e._v("The core components of insertion part is split. Highly recommend to use pen and paper to figure how bucket split works before coding.")]),e._v(" "),t("p",[e._v("The insertion procedure is as follows:")]),e._v(" "),t("ol",[t("li",[e._v("Find the right bucket")]),e._v(" "),t("li",[e._v("If there is room in the bucket, insert the KV pair")]),e._v(" "),t("li",[e._v("If there is no room -> split the bucket")])]),e._v(" "),t("p",[e._v("How to split one bucket? Assume we call the split target "),t("em",[e._v("split bucket")]),e._v(" and the newly created bucket "),t("em",[e._v("image bucket")]),e._v(".")]),e._v(" "),t("ul",[t("li",[t("p",[e._v("If $ global\\_depth == local\\_depth $:")]),e._v(" "),t("ul",[t("li",[e._v("Increase the "),t("code",[e._v("global_depth")]),e._v(" by 1, so double the table size")]),e._v(" "),t("li",[e._v("The following steps are same as situation $ global\\_depth > local\\_depth $")])])]),e._v(" "),t("li",[t("p",[e._v("If $global\\_depth > local\\_depth$:")]),e._v(" "),t("ul",[t("li",[e._v("Allocate a new page for the image bucket")]),e._v(" "),t("li",[e._v("Adjust the entries in the bucket address table\n"),t("ul",[t("li",[e._v("leave the half of the entries pointing to the split bucket")]),e._v(" "),t("li",[e._v("set all the remaining entries to point to the image bucket")]),e._v(" "),t("li",[e._v("also increase the "),t("code",[e._v("local_depth")]),e._v(" by 1 because we need one more bit to separate them")])])]),e._v(" "),t("li",[e._v("Rehash KV pairs in the split bucket")]),e._v(" "),t("li",[e._v("Re-attemp the insertion\n"),t("ul",[t("li",[e._v("Should use the "),t("code",[e._v("Insert()")]),e._v(" function because we may need more splits")])])])])])]),e._v(" "),t("p",[e._v("Add your own test cases. The given test case is so small and cannot cover all situations.")]),e._v(" "),t("h3",{attrs:{id:"remove"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#remove"}},[e._v("#")]),e._v(" Remove")]),e._v(" "),t("p",[e._v("Remove itself is very simple. The complicated part is the merge procedure. The good thing is that, after finished split, the logic of merge became clear to us.")]),e._v(" "),t("p",[e._v("The project description gives a fairly thorough instructions for merge. Follow the instruction is enough.")]),e._v(" "),t("p",[e._v("Shrinking the table is very straightforward since we use LSB to assign KV pairs to different buckets.")]),e._v(" "),t("h2",{attrs:{id:"task-3-concurrency-control"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#task-3-concurrency-control"}},[e._v("#")]),e._v(" Task #3 Concurrency Control")]),e._v(" "),t("p",[e._v("Try coarse-grained latch (lock) first, then reduce the latch range.")]),e._v(" "),t("p",[e._v("No special comments for this. You can do it!")]),e._v(" "),t("h2",{attrs:{id:"result"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#result"}},[e._v("#")]),e._v(" Result")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/z1ggy-o/static_resources/main/img/cmu15445-project02-grades.png",alt:"grades"}})])])}),[],!1,null,null,null);t.default=o.exports}}]);